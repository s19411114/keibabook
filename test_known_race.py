#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
çµ±åˆãƒ†ã‚¹ãƒˆ: éå»ã®æœ‰åŠ¹ãªæ—¥ä»˜ã§ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import sys
from datetime import datetime, timedelta
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from src.utils.schedule_manager import ScheduleManager
from src.scrapers.race_scraper import RaceScraper
from src.utils.db_manager import CSVDBManager
from src.utils.logger import get_logger

logger = get_logger(__name__)


async def test_with_specific_race():
    """æ—¢çŸ¥ã®ãƒ¬ãƒ¼ã‚¹IDã§ç›´æ¥ãƒ†ã‚¹ãƒˆ"""
    print("=" * 70)
    print("ğŸš€ çµ±åˆãƒ†ã‚¹ãƒˆ: æ—¢çŸ¥ã®ãƒ¬ãƒ¼ã‚¹IDã§ãƒ‡ãƒ¼ã‚¿å–å¾—")
    print("=" * 70)
    
    # æ—¢çŸ¥ã®æœ‰åŠ¹ãªãƒ¬ãƒ¼ã‚¹IDï¼ˆdata/json/ã«å­˜åœ¨ã™ã‚‹ã‚‚ã®ï¼‰
    test_race_id = "202505040611"  # ç¦å³¶5R
    
    print(f"\nğŸ ãƒ†ã‚¹ãƒˆå¯¾è±¡: {test_race_id}")
    print("-" * 70)
    
    # 1. RaceScraperã§ãƒ‡ãƒ¼ã‚¿å–å¾—
    scraper = RaceScraper()
    try:
        race_data = await scraper.scrape_race(test_race_id)
        
        if race_data:
            print(f"\nâœ… ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ!")
            print(f"  ãƒ¬ãƒ¼ã‚¹ID: {race_data.get('race_id', 'ä¸æ˜')}")
            print(f"  ãƒ¬ãƒ¼ã‚¹å: {race_data.get('race_name', 'ä¸æ˜')}")
            print(f"  å‡ºèµ°é¦¬æ•°: {len(race_data.get('horses', []))}")
            print(f"  CPUäºˆæƒ³æ•°: {len(race_data.get('cpu_prediction', []))}")
            
            # CPUäºˆæƒ³ã‚’è¡¨ç¤º
            cpu_pred = race_data.get('cpu_prediction', [])
            if cpu_pred:
                print(f"\n  ğŸ’¡ CPUäºˆæƒ³ TOP 5:")
                for i, pred in enumerate(cpu_pred[:5], 1):
                    print(f"    {i}ä½: {pred.get('horse_name', 'ä¸æ˜')}")
            
            # å‡ºèµ°é¦¬ã‚’è¡¨ç¤º
            horses = race_data.get('horses', [])
            if horses:
                print(f"\n  ğŸ´ å‡ºèµ°é¦¬ ({len(horses)}é ­):")
                for horse in horses[:5]:
                    print(f"    {horse.get('number', '?')}ç•ª: {horse.get('name', 'ä¸æ˜')}")
                if len(horses) > 5:
                    print(f"    ... ä»–{len(horses)-5}é ­")
            
            # JSONã§ä¿å­˜
            import json
            output_dir = Path("data/json/test")
            output_dir.mkdir(parents=True, exist_ok=True)
            output_file = output_dir / f"{test_race_id}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(race_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_file}")
            
            # 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ãƒ†ã‚¹ãƒˆ
            print(f"\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ãƒ†ã‚¹ãƒˆ")
            print("-" * 70)
            
            db_manager = CSVDBManager()
            
            # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            schedule_data = [{
                'venue': 'ç¦å³¶',
                'race_type': 'jra',
                'races': [{
                    'race_num': 6,
                    'time': '11:25',
                    'race_id': test_race_id
                }]
            }]
            
            db_manager.save_schedule(schedule_data, "2025-05-04")
            print("âœ… ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ä¿å­˜å®Œäº†")
            
            print("\n" + "=" * 70)
            print("âœ… çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†!")
            print("=" * 70)
            return True
            
        else:
            print("âŒ ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        return False
        
    finally:
        await scraper.close()


if __name__ == '__main__':
    success = asyncio.run(test_with_specific_race())
    sys.exit(0 if success else 1)
