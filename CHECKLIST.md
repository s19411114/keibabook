# 動作確認チェックリスト

## セットアップ確認

- [ ] 仮想環境が作成されている
- [ ] `pip install -r requirements.txt` が完了
- [ ] `playwright install chromium` が完了
- [ ] `config/settings.yml` が正しく設定されている

## 基本動作確認

### 1. CLI版の動作確認
```bash
python run_scraper.py
```
- [ ] エラーなく実行できる
- [ ] `data/` ディレクトリにJSONファイルが作成される
- [ ] `data/db/` ディレクトリにCSVファイルが作成される

### 2. Streamlit GUIの動作確認
```bash
streamlit run app.py
```
- [ ] ブラウザでGUIが開く
- [ ] サイドバーに設定が表示される
- [ ] スクレイピングタブが表示される
- [ ] データ確認タブが表示される
- [ ] レコメンドタブが表示される
- [ ] ログタブが表示される

## スクレイピング機能確認

### 3. データ取得確認
- [ ] 出馬表ページからレース情報が取得できる
- [ ] 調教データが取得できる
- [ ] 血統データが取得できる
- [ ] コメントデータが取得できる
- [ ] 馬柱から過去3走分が取得できる（実際のHTML構造に応じて調整が必要）

### 4. データ保存確認
- [ ] JSONファイルが正しく保存される
- [ ] CSVファイルが正しく保存される
- [ ] 重複チェックが機能する（2回目実行時にスキップされる）

## レコメンド機能確認

### 5. 過小評価馬検出
- [ ] レースデータを読み込める
- [ ] 過小評価馬検出ボタンが動作する
- [ ] 検出結果が正しく表示される

### 6. 成績分析
- [ ] 馬を選択できる
- [ ] 分析実行ボタンが動作する
- [ ] 分析結果が正しく表示される

## トラブルシューティング

### よくあるエラー

1. **ModuleNotFoundError**
   - 仮想環境がアクティベートされているか確認
   - `pip install -r requirements.txt` を再実行

2. **Playwrightブラウザエラー**
   - `playwright install chromium` を再実行
   - `playwright install --force chromium` を試す

3. **設定ファイルエラー**
   - `config/settings.yml` のパスが正しいか確認
   - YAMLの構文エラーがないか確認

4. **馬柱データが取得できない**
   - `debug_page.html` を確認してHTML構造を把握
   - `src/scrapers/keibabook.py` の `_parse_horse_table_data` のセレクタを調整

## 次のステップ

動作確認が完了したら：
1. 実際のレースでスクレイピングを実行
2. 取得したデータを確認
3. 必要に応じてパーサーを調整
4. データ蓄積を開始

