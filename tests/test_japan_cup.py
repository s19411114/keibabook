#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""ã‚¸ãƒ£ãƒ‘ãƒ³ã‚«ãƒƒãƒ— ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ"""

import sys
import asyncio
import yaml
from pathlib import Path
sys.path.insert(0, 'src')

from scrapers.keibabook import KeibaBookScraper

async def test_japan_cup():
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    config_path = Path('config/settings.yml')
    with open(config_path, 'r', encoding='utf-8') as f:
        settings = yaml.safe_load(f)
    
    # 2024å¹´ã‚¸ãƒ£ãƒ‘ãƒ³ã‚«ãƒƒãƒ—: 11æœˆ24æ—¥ æ±äº¬11R
    race_id = '2024112411'
    
    # URLã‚’è¨­å®š
    shutuba_url = f'https://www.keibabook.co.jp/sp/shutuba.aspx?RaceID={race_id}'
    
    scraper = KeibaBookScraper(settings)
    scraper.shutuba_url = shutuba_url
    
    print(f'ğŸ å–å¾—é–‹å§‹: {race_id} (2024å¹´ã‚¸ãƒ£ãƒ‘ãƒ³ã‚«ãƒƒãƒ—)')
    print(f'URL: {shutuba_url}')
    print('-' * 50)
    
    try:
        data = await scraper.scrape()
        
        if data:
            print('âœ… ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ')
            print(f'ãƒ¬ãƒ¼ã‚¹å: {data.get("race_name", "ä¸æ˜")}')
            print(f'é¦¬æ•°: {len(data.get("horses", []))}')
            
            # é¦¬åãƒªã‚¹ãƒˆ
            if data.get('horses'):
                print('\nå‡ºèµ°é¦¬:')
                for i, horse in enumerate(data['horses'][:5], 1):
                    print(f"  {i}. {horse.get('horse_name', 'ä¸æ˜')}")
                if len(data['horses']) > 5:
                    print(f"  ... ä»– {len(data['horses']) - 5} é ­")
                    
            # JSONä¿å­˜
            import json
            output_path = Path('data') / 'json' / f'{race_id}.json'
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f'\nğŸ’¾ ä¿å­˜: {output_path}')
        else:
            print('âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—')
    
    except Exception as e:
        import traceback
        print(f'âŒ ã‚¨ãƒ©ãƒ¼: {e}')
        traceback.print_exc()
    
    finally:
        # ãƒ–ãƒ©ã‚¦ã‚¶ã‚¯ãƒ­ãƒ¼ã‚º
        if hasattr(scraper, '_playwright') and scraper._playwright:
            await scraper._playwright.__aexit__(None, None, None)

if __name__ == '__main__':
    asyncio.run(test_japan_cup())
