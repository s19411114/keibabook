#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""æœ¬æ—¥ã®æ±äº¬12Rã®ãƒ¬ãƒ¼ã‚¹IDã‚’KeibaBookã‹ã‚‰ç›´æ¥å–å¾—"""

import sys
import asyncio
from datetime import datetime
sys.path.insert(0, 'src')

from scrapers.race_scraper import RaceScraper

async def find_race():
    # æœ¬æ—¥ã®æ—¥ä»˜ã‹ã‚‰è€ƒãˆã‚‰ã‚Œã‚‹ãƒ¬ãƒ¼ã‚¹IDå½¢å¼ã‚’è©¦è¡Œ
    today = datetime.now()
    
    # KeibaBookã®å½¢å¼: YYYYMMDD + ä¼šå ´ã‚³ãƒ¼ãƒ‰ + ãƒ¬ãƒ¼ã‚¹ç•ªå·
    # æ±äº¬: 05, 12R: 12
    race_id_pattern = f"{today.year}{today.month:02d}{today.day:02d}0512"
    
    print(f"ğŸ” è©¦è¡Œã™ã‚‹ãƒ¬ãƒ¼ã‚¹ID: {race_id_pattern}")
    print(f"ğŸ“… æ—¥ä»˜: {today.year}å¹´{today.month}æœˆ{today.day}æ—¥")
    print(f"ğŸ‡ ä¼šå ´: æ±äº¬ (ã‚³ãƒ¼ãƒ‰: 05)")
    print(f"ğŸ ãƒ¬ãƒ¼ã‚¹: 12R")
    print("-" * 60)
    
    scraper = RaceScraper()
    try:
        url = f"https://www.keibabook.co.jp/sp/shutuba.aspx?RaceID={race_id_pattern}"
        print(f"ğŸ“ URL: {url}")
        
        data = await scraper.scrape_race(race_id_pattern)
        
        if data:
            print(f"\nâœ… ãƒ¬ãƒ¼ã‚¹ç™ºè¦‹!")
            print(f"ãƒ¬ãƒ¼ã‚¹å: {data.get('race_name', 'ä¸æ˜')}")
            print(f"é¦¬æ•°: {len(data.get('horses', []))}")
            if data.get('cpu_prediction'):
                print(f"CPUäºˆæƒ³é¦¬æ•°: {len(data['cpu_prediction'])}")
                print("\nğŸ CPUäºˆæƒ³ä¸Šä½3é ­:")
                for i, horse in enumerate(data['cpu_prediction'][:3], 1):
                    print(f"  {i}ä½: {horse.get('horse_name', 'ä¸æ˜')}")
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    finally:
        await scraper.close()

if __name__ == '__main__':
    asyncio.run(find_race())
